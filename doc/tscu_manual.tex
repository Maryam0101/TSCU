\documentclass{article}
\usepackage{fullpage}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[config, labelfont=scriptsize, textfont=scriptsize]{subfig}
\newcommand{\B}[1]{\boldsymbol{#1}}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\usepackage{amsmath,epsfig}
\usepackage{eqparbox}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{algpseudocode}
\usepackage{algorithm}
%\renewcommand{\thesubfigure}{\arabic{subfigure}}

\title{Time Series Classification Utility\\
User Manual} 
\author{H\"useyin Kaya}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
Time Series Classification Utility (TSCU) is a simple MATLAB program that you can use it to classify time series by choosing a couple of alignment methods including Dynamic Time Warping (DTW), Constrained DTW (CDTW) and Signal Alignment via Genetic Algorithm (SAGA).

I decided to prepare TSCU during my PhD which is about creating a new time series alignment algorithm and its application to various real-world problems. There were (and there are still) a bunch of useful tools for time series alignment, but none of them seem to provide a general framework for classification \cite{UCRWeb}. I also wanted to create a useful website so that people searching for a time series classification task will find all crucial information quickly.
\section{Installation}
TSCU is freely available from GitHub. Majority of the code lies in just one MATLAB script: tscu.m. However it is recommended to fetch the whole repository (which is about 1Mb) in order to obtain a few dependent files. You can use the following command to download the repository:
\begin{verbatim}
git clone https://github.com/hkayabilisim/TSCU.git
\end{verbatim}
This will checkout the repository into a new directory named TSCU.
After downloading the source code, you should follow the following steps.

\begin{itemize}
\item In order to use the alignment methods DTW and constrained DTW, you should compile the mex file dtw.c by issuing the following command on MATLAB:
\begin{verbatim}
mex dtw.c
\end{verbatim}

\item If everyting goes well, you will have a new executable file with extension name begins with mex. In my Macbook Pro, its name is dtw.mexmaci64. If you have problems in compiling the mex file (you are very likely to face such problems, by the way), then you can look for precompiled binaries on TSCU repository.

\item If you want to test the utility with the University of California, Riverise (UCR) time series repository, then you should request the dataset from Eamonn Keogh personally because I don't have permission to provide the dataset \cite{UCRWeb}. I strongly suggest you to have a copy of this large and diverse dataset if you want to do detailed analysis on alignment techniques.

\item If you want to test the alignment algorithm Signal Alignment via Genetic Algorithm (SAGA), you should have Genetic Algorithm Toolbox of MATLAB. SAGA is optional, so if you don't have this toolbox, don't bother. You can still use DTW or constained DTW for alignment.

\item The cost function used in SAGA can be replaced with its MEX counterpart \texttt{'Jcost1.c'} which includes a single LAPACK call \texttt{dgesv}. You should first compile it by using the \texttt{'make.m'} script which includes a couple of alternative ways. On MacOSX systems, Acceleration framework can be used as follows:
\begin{verbatim}
mex  Jcost1.c  CLIBS="\$CLIBS -framework Accelerate" -largeArrayDims 
\end{verbatim}

If, for some reason, you don't want to use Accelaration framework, then you can always compile LAPACK by yourself. In this case, compiling the MEX file is tricky. In addition to the lapack library, you have to build the BLAS and LAPACKE libraries. Finally, if you use \texttt{gfortran} compiler, then you should link the related library. The same is true for Intel Fortran compiler. Here are two example cases:

\begin{verbatim}
mex Jcost1.c CLIBS="\$CLIBS -L lapack/MACOSXgfortran  -llapacke -llapack -lrefblas \
 -L     /opt/local/lib/gcc44 -lgfortran"
mex Jcost1.c CLIBS="\$CLIBS -L lapack/Linuxifort -llapacke -llapack -lrefblas \
 -L /RS/progs/intel/lib/intel64 -lifcore -lirc"
\end{verbatim}

There is no significant performance gain if you choose to use the Accelaration framework. Yet
another alternative would be to use ATLAS which I haven't tried yet. 
\end{itemize}



\section{Running}
A straightforward way yo to test the installation is to run a few tasks. Let's start with the Synthetic Control dataset from University of California-Riverside (UCR) time series repository. This dataset is freely available on UCR time repository web page\footnote{http://www.cs.ucr.edu/~eamonn/time\_series\_data/.}. There are $6$ different classes of time series each has length $60$. There are totally $600$ time series half of it is reversed for training. Some examples of the dataset are displayed in Figure~\ref{fig_synthetic}.

	\begin{figure}[!h]
	\centering
	\subfloat[normal]{\includegraphics[width=0.33\textwidth]{../Experiment59-synthetic-control-01.pdf}}%
	\subfloat[cyclic]{\includegraphics[width=0.33\textwidth]{../Experiment59-synthetic-control-02.pdf}}%
	\subfloat[increasing trend]{\includegraphics[width=0.33\textwidth]{../Experiment59-synthetic-control-03.pdf}}\\%
	\subfloat[decreasing trend]{\includegraphics[width=0.33\textwidth]{../Experiment59-synthetic-control-04.pdf}}%
	\subfloat[upward shift]{\includegraphics[width=0.33\textwidth]{../Experiment59-synthetic-control-05.pdf}}%
	\subfloat[downward shift]{\includegraphics[width=0.33\textwidth]{../Experiment59-synthetic-control-06.pdf}}%
	\caption{Some examples from 6 different control charts used in the synthetic control dataset.}
	\label{fig_synthetic}
	\end{figure}

After downloading training and testing set, you can classify the time series in the testing set by using the following command:
\begin{scriptsize}
\begin{verbatim}
>> trn=load('synthetic_control_TRAIN');
>> tst=load('synthetic_control_TEST');
>> tscu(trn,tst)

Size of training set.....................: 300
Size of testing set......................: 300
Time series length.......................: 60
Classification method....................: 1-NN
Alignment method.........................: None
Overall Accuracy.........................: 0.880   
Overall Error............................: 0.120   
Producer Accuracy........................: 0.440   1.000   0.980   1.000   0.940   0.920   
User Accuracy............................: 1.000   0.833   0.891   0.862   0.887   0.885   
Kappa....................................: 0.856   
Z-value..................................: 5.439   
Confusion matrix
          1     2     3     4     5     6    UA    TO 
    1    22     0     0     0     0     0 1.000    22 
    2    10    50     0     0     0     0 0.833    60 
    3     3     0    49     0     3     0 0.891    55 
    4     4     0     0    50     0     4 0.862    58 
    5     5     0     1     0    47     0 0.887    53 
    6     6     0     0     0     0    46 0.885    52 
   PA 0.440 1.000 0.980 1.000 0.940 0.920 
   TO    50    50    50    50    50    50         300 
Time elapsed (sec).......................: 1.08 
\end{verbatim}
\end{scriptsize}
Output of TSCU is pretty self-explanatory.  As you see from the output, TSCU does not use an alignment algorithm in its default form. Overall error in this case is $0.12$ which is the same as the published error on UCR web site. TSCU also outputs confusion matrix which can sometimes be usefull for further analysis.

If you want to use Dynamic Time Warping (DTW) as the alignmnt method for the same dataset, then you can append the following options:
\begin{scriptsize}
\begin{verbatim}
>> trn=load('synthetic_control_TRAIN');
>> tst=load('synthetic_control_TEST');
>> tscu(trn,tst,'alignment','DTW')

Size of training set.....................: 300
Size of testing set......................: 300
Time series length.......................: 60
Classification method....................: 1-NN
Alignment method.........................: DTW
Overall Accuracy.........................: 0.993   
Overall Error............................: 0.007   
Producer Accuracy........................: 0.960   1.000   1.000   1.000   1.000   1.000   
User Accuracy............................: 1.000   0.980   1.000   1.000   0.980   1.000   
Kappa....................................: 0.992   
Z-value..................................: 24.884  
Confusion matrix
          1     2     3     4     5     6    UA    TO 
    1    48     0     0     0     0     0 1.000    48 
    2     1    50     0     0     0     0 0.980    51 
    3     0     0    50     0     0     0 1.000    50 
    4     0     0     0    50     0     0 1.000    50 
    5     1     0     0     0    50     0 0.980    51 
    6     0     0     0     0     0    50 1.000    50 
   PA 0.960 1.000 1.000 1.000 1.000 1.000 
   TO    50    50    50    50    50    50         300 
Time elapsed (sec).......................: 5.77  
\end{verbatim}
\end{scriptsize}


You can find more examples and their corresponding outputs on \verb|html| directory.
\section{Options}
There are varios options that you may want to use. Each option should be given with a key-value pair like \texttt{tscu(trn,tst,'Option1','value1','Option2','value2')}. Available options can be listed by running \texttt{help tscu} or \texttt{doc tscu} on MATLAB assuming that \texttt{tscu.m} is on the working directory or in the path.

\subsection{\texttt{'Classifier'}}
This option sets the classifier that is used to classify the instances in training and testing sets. Currently you can only set \texttt{'K-NN'} classifier. \texttt{'K-NN'} is also the default classfier with $K=1$.

\subsection{\texttt{'Alignment'}} 
This option specifies the alignment algorithm used in distance calculation between any two time series. The following values are available.

\subparagraph*{\texttt{'None'}} {\it (default)} In this case no alignment takes place and usual Euclidean distance between two time series is taken as the distance.

\subparagraph*{\texttt{'DTW'}} Standard Dynamic Time Warping is used in its original simple form without any lower bounding or bands. The implementation is based on The UCR Suite\footnote{http://www.cs.ucr.edu/\%7Eeamonn/UCRsuite.html}. The code is written as a MATLAB MEX file to gain some speed. However one should compile the mex file {\it dtw.c} to be able to use it in TSCU. 

\subparagraph*{\texttt{'CDTW'}} Constrained Dynamic Time Warping in which the path is constrained in Sakoe-Chiba band. It is implemented again in the same mex file {\it dtw.c} however one should use the additional option \texttt{'DTWbandwidth'} to set the width of the band.

\subparagraph*{\texttt{'SAGA'}} Signal Alignment via Genetic Algorithm. It uses smooth monotone functions suggested by Ramsay\cite{Ramsay1998}, but solves the best parameter set by using Genetic Algorithm\cite{Kaya2013113}. It is more accurate but slower than others.


 
\subsection{\texttt{'DTWbandwidth'}} 
\subparagraph*{$6$} {\it default} This parameter is used when one choose \texttt{'CDTW'} as the alignment method. It is the width of the Sakoe-Chiba band defined in percentage. Setting it to $100$ is the same effect as running DTW.

\subsection{\texttt{'SAGACostFunction'}} 
This options specifies the cost function used in SAGA. The speed of SAGA is directly affected with this choice. If you set this option but not choose SAGA as the alignment method, it will be silently ignored.

All cost functions calculates the distance below 
$$ d = || x - y(w(t)) ||$$
where $x$ and $y$ are the time series and $w(t)$ is the warping path determined by the alignment algorithm. Warping function $w$ is obtained by solving an ODE suggested by Ramsay \cite{Ramsay1998}. The weight vector of the ODE is the free variable of the cost function. There are different implementations of the cost function.

\subparagraph*{\texttt{'Jcost0'}} This implementation of the cost function first discretizes the unit interval and obtains a time vector whose length is equal to the length of time series. Then,  it solves the ODE by using the weight vector in order to find the warping path. One of the time series is warped by using the warping function. Warping is achieved by using  linear interpolation. Finally the Euclidean distance between the warped time series and the unwarped one is calculated. The related MATLAB implementation is shown below. Solution of ODE, interpolation and Euclidean distance are all conducted in MATLAB without depending any other software. So it is rather slow but portable i.e. you don't need to compile a MEX file, everything you need is in the package. 
\begin{verbatim}
t=linspace(0,1,length(x));
J = @(s) norm(interp1(t,y,ramsay(t,s))-x);
\end{verbatim}

\subparagraph*{\texttt{'Jcost1'}} This cost function is equivalent of \texttt{'Jcost0'} but it is rewritten as a MEX file (\texttt{'Jcost1.c'}) in order to gain some speed. The MEX file itself uses a LAPACK call (\texttt{dgesv}) to solve a linear system of equation. It is almost three times faster than \texttt{'Jcost0'}. However, you should be able to compile the MEX file \texttt{'Jcost1.c'}. Further information on compiling can be found in \S Installation.

\subsection*{\texttt{'SAGAOptimizationMethod'}}
The alignment method SAGA relies on minimization of the cost function defined in \texttt{'SAGACostFunction'}. By default, minimization of the cost function is achieved by using Genetic Algorithm. However some other optimization techniques may also be used.

\subparagraph*{\texttt{'GA'}} {\it (default)} By default genetic algorithm is used to find the minimum point of the cost function.

\subparagraph*{\texttt{'Simplex'}} By choosing this value, Nelder-Mead Simplex method is used as a minimization routing \cite{Lagarias1998}. It requires an initial point which can be specified with \texttt{'InitialSolution'} option.

\subsection{\texttt{'SAGAInitialSolution'}}
Some of the optimization algorithms specified in \texttt{'SAGAOptimizationMethod'} option may need an initial solution. For instance \texttt{'Simplex'} requires a starting point. By default it is set to zero vector with length \texttt{'SAGABaseLength'}.

\subsection{\texttt{'SAGABaseLength'}} 
It is the number of spline bases used in ODE proposed by Ramsay. Default value is $8$.

\subsection{\texttt{'LogLevel'}}
There are eight log levels whose range starts from ``absolute silence'' to ``display everything'': \texttt{'Emergency'}, \texttt{'Alert'}, \texttt{'Critical'}, \texttt{'Error'}, \texttt{'Warning'}, \texttt{'Notice'}, \texttt{'Info'} ({\it default}),and \texttt{'Debug'}.  

\subsection{\texttt{'MATLABPool'}}
If your MATLAB distribution includes Parallel Computing Toolbox, then one can feed the name of parallel pool into TSCU so that any suitable loop is run parallel. If your computer has a multi-core CPU and you have this toolbox, setting this option to \texttt{'local'} will enable MATLAB to distribute the workload to the available cores. Currently, only the ``for'' loops related with K-NN classifier have been converted to ``parfor'' counterparts. If you choose K-NN and enable this option, it is high likely to get a speed-up of factor 4 by using a quad-core processor.

\subsection{\texttt{'DisplayInputData'}}
If it is set to \texttt{'yes'}, training and testing data will be displayed before classification.

\subsection{\texttt{'trainingRatio'}}
If the data is not already divided, it is divided  into training and testing set
%   trainingRatio: Ratios of training set to the whole set of training
%    and testing. Defined between (0,1).
%    default : 0.30

\section{Examples}
In order to classify synthetic control dataset with default options you can use the following commands provided that you first downloaded the dataset:
\begin{verbatim}
trn=load('synthetic_control_TRAIN');
tst=load('synthetic_control_TEST');

tscu(trn,tst)
\end{verbatim}
You can specify the alignment algorithm by using the option \texttt{'alignment'}. For instance:
\begin{verbatim}
tscu(trn,tst,'alignment','DTW')
\end{verbatim}
choose good old Dynamic Time Warping method. In order use constrained DTW, you can use \texttt{'CDTW'} together with \texttt{'DTWbandwidth'}.
\begin{verbatim}
tscu(trn,tst,'alignment','CDTW','DTWbandwidth',6)
\end{verbatim}

\section{Known issues}
\begin{itemize}
\item TSCU can not use multi-channel time series. However, one can first reduce the number of channels to a single channel by using straightforward technique of summing the channels or by using some other dimensional reduction algorithms. Choosing the right approach really depends on the application, so I didn't implement such methods in TSCU. Channel reduction is left to the responsibility of the user.
\item \texttt{'Jcost1'} is slower than \texttt{'Jcost0'} although the former is written in MEX.
\end{itemize}
\bibliographystyle{unsrt}
\bibliography{references}


\end{document}
